{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cdedd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "import os, sys, pathlib\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from mlqm import DEFAULT_TENSOR_TYPE\n",
    "tf.keras.backend.set_floatx(DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "# For the wavefunction:\n",
    "from mlqm.models import ManyBodyWavefunction\n",
    "from mlqm.config import ManyBodyCfg\n",
    "\n",
    "# For the hamiltonian:\n",
    "from mlqm.hamiltonians import Hamiltonian\n",
    "from mlqm.config import NuclearHamiltonian as H_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e48b2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_inputs(nwalkers, nparticles, ndim, n_spin_up, n_protons):\n",
    "\n",
    "    inputs = numpy.random.uniform(size=[nwalkers, nparticles, ndim])\n",
    "\n",
    "\n",
    "    # Note that we initialize with NUMPY for ease of indexing and shuffling\n",
    "    spin_walkers = numpy.zeros(shape=(nwalkers, nparticles)) - 1\n",
    "    for i in range(n_spin_up):\n",
    "        if i < spin_walkers.shape[-1]:\n",
    "            spin_walkers[:,i] += 2\n",
    "\n",
    "    # Shuffle the spin up particles on each axis:\n",
    "\n",
    "    # How to compute many permutations at once?\n",
    "    #  Answer from https://stackoverflow.com/questions/5040797/shuffling-numpy-array-along-a-given-axis\n",
    "    # Bottom line: gen random numbers for each axis, sort only in that axis,\n",
    "    # and apply the permutations\n",
    "    idx = numpy.random.rand(*spin_walkers.shape).argsort(axis=1)\n",
    "    spin_walkers = numpy.take_along_axis(spin_walkers, idx, axis=1)\n",
    "\n",
    "    # Note that we initialize with NUMPY for ease of indexing and shuffling\n",
    "    isospin_walkers = numpy.zeros(shape=(nwalkers, nparticles)) - 1\n",
    "    for i in range(n_protons):\n",
    "        if i < isospin_walkers.shape[-1]:\n",
    "            isospin_walkers[:,i] += 2\n",
    "\n",
    "    # Shuffle the spin up particles on each axis:\n",
    "\n",
    "    # How to compute many permutations at once?\n",
    "    #  Answer from https://stackoverflow.com/questions/5040797/shuffling-numpy-array-along-a-given-axis\n",
    "    # Bottom line: gen random numbers for each axis, sort only in that axis,\n",
    "    # and apply the permutations\n",
    "    idx = numpy.random.rand(*isospin_walkers.shape).argsort(axis=1)\n",
    "    isospin_walkers = numpy.take_along_axis(isospin_walkers, idx, axis=1)\n",
    "\n",
    "    return inputs, spin_walkers, isospin_walkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bbed5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_derivatives(\n",
    "    wavefunction : tf.keras.models.Model,\n",
    "    inputs : tf.Tensor,\n",
    "    spin : tf.Tensor,\n",
    "    isospin : tf.Tensor = None):\n",
    "\n",
    "    n_walkers = inputs.shape[0]\n",
    "    n_particles = inputs.shape[1]\n",
    "    n_dim = inputs.shape[2]\n",
    "\n",
    "    # Turning off all tape watching except for the inputs:\n",
    "    # Using the outer-most tape to watch the computation of the first derivative:\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Use the inner tape to watch the computation of the wavefunction:\n",
    "        tape.watch(inputs)\n",
    "        with tf.GradientTape() as second_tape:\n",
    "            second_tape.watch(inputs)\n",
    "            w_of_x = wavefunction(inputs, spin, isospin)\n",
    "            # w_of_x = tf.reshape(sign, (-1, 1)) * tf.exp(logw_of_x)\n",
    "        # Get the derivative of logw_of_x with respect to inputs\n",
    "        print(w_of_x)\n",
    "        dw_dx = second_tape.gradient(w_of_x, inputs)\n",
    "#         dw_dx = tf.reshape(dw_dx, (n_walkers, n_particles, n_dim))\n",
    "#         print(dw_dx)\n",
    "\n",
    "    # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "    # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "    # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "    # The indexes represent partial derivative indexes, so,\n",
    "    # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "    # wavefunction at dimension d1\n",
    "\n",
    "    # This is the full hessian computation:\n",
    "    d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "\n",
    "    print(d2w_dx2)\n",
    "\n",
    "    # # Extract the diagonal parts:\n",
    "    # d2w_dx2 = tf.vectorized_map(tf.linalg.tensor_diag_part, d2w_dx2)\n",
    "\n",
    "    # # And this contracts:\n",
    "    d2w_dx2 = tf.einsum(\"wpdpd->wpd\",d2w_dx2)\n",
    "    #\n",
    "    # print(\"First einsum: \", d2w_dx2[0])\n",
    "    #\n",
    "    # print(\"Method diff 0: \", d2w_dx2_t[0] - d2w_dx2[0])\n",
    "    # # TODO: test that the second derivative is correct with finite differences\n",
    "\n",
    "    return w_of_x, dw_dx, d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff5b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers   = 1\n",
    "nparticles = 2\n",
    "ndim       = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50436eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, spins, isospins = generate_inputs(nwalkers, nparticles, ndim, 2, 1)\n",
    "xinputs = tf.convert_to_tensor(\n",
    "    inputs - numpy.reshape(numpy.mean(inputs, axis=1), (nwalkers, 1, ndim)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "675a4e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(isospins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53fe1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    " c = ManyBodyCfg()\n",
    "\n",
    "c = OmegaConf.structured(c)\n",
    "w = ManyBodyWavefunction(ndim, nparticles, c,\n",
    "    n_spin_up = 2, n_protons = 1,\n",
    "    use_spin = True, use_isospin = True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd6276e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c41d896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00074885]], shape=(1, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[[[ 0.01066629]\n",
      "    [-0.01066629]]]\n",
      "\n",
      "\n",
      "  [[[-0.01066629]\n",
      "    [ 0.01066629]]]]], shape=(1, 2, 1, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "w_local = w(xinputs, spins, isospins)\n",
    "\n",
    "\n",
    "w_of_x, dw_dx, d2w_dx2 = compute_derivatives(w, xinputs, spins, isospins)\n",
    "\n",
    "dw_dx = dw_dx.numpy()\n",
    "d2w_dx2 = d2w_dx2.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5182231e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.00074885]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43c59b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_of_x - w_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a78022c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_numerical_derivatives(f, x, s, i, dim, part, kick_size=1e-4):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    nparticles = x.shape[1]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape)\n",
    "    kick_size = 1e-4\n",
    "    \n",
    "    walkers = numpy.arange(nwalkers)\n",
    "\n",
    "    if len(kick.shape) == 3:\n",
    "        # Not single-particle\n",
    "        kick[walkers,part, dim] += kick_size\n",
    "    elif len(kick.shape) == 2:\n",
    "        # single particle:\n",
    "        kick[walkers, dim] += kick_size\n",
    "\n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x + 2*dx:\n",
    "#     kicked_double_up_input = x + \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x - 2*dx\n",
    "#     kicked_double_down_input = x - \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x, s, i)\n",
    "    w_up = f(kicked_up_input, s, i)\n",
    "    w_down = f(kicked_down_input, s, i)\n",
    "#     w_up_up = f(kicked_double_up_input, s, i)\n",
    "#     w_down_down = f(kicked_double_down_input, s, i)\n",
    "\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "#     w_prime_prime_num = -w_down_down + 16*w_down - 30* w_of_x + 16 * w_up - w_up_up\n",
    "    w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "147bc9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00238138]\n",
      "  [ 0.00238138]]]\n",
      "[[[0.00195842]\n",
      "  [0.00195842]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first = []\n",
    "second = []\n",
    "for dim in range(ndim):\n",
    "    first.append([])\n",
    "    second.append([])\n",
    "    for part in range(nparticles):\n",
    "\n",
    "        t_num_dw_dx, t_num_d2w_dx2 = compute_numerical_derivatives(w, xinputs, spins, isospins, dim, part, kick_size=1e-6)\n",
    "        first[dim].append(t_num_dw_dx)\n",
    "        second[dim].append(t_num_d2w_dx2)\n",
    "    # At the end of the loop, the list should be length n_particles, with nwalker entries each.\n",
    "    # stack and flip it\n",
    "    first[-1] = numpy.stack(first[-1]).T\n",
    "    second[-1] = numpy.stack(second[-1]).T\n",
    "\n",
    "num_dw_dx = numpy.stack(first, axis=-1)\n",
    "num_d2w_dx2 = numpy.stack(second, axis=-1)\n",
    "print(num_dw_dx)\n",
    "print(num_d2w_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe13c35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.18258155e-11],\n",
       "        [-1.18258155e-11]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dw_dx - dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c653b031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.00870786],\n",
       "        [-0.00870786]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d2w_dx2 - d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7e2cb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_l_of_x, o_dl_dx, o_d2l_dx2 = h.compute_derivatives(l, xinputs, spins, other_isospins)\n",
    "o_fd_dl_dx, o_fd_d2l_dx2 = compute_numerical_derivatives(l, xinputs, spins, other_isospins,part,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "d60165e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([3.11348447e-11, 2.85769741e-11, 3.43116646e-11])>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_fd_dl_dx - o_dl_dx[:,part,dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "916ebb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 6.36841540e-10,  2.49571932e-09, -3.08548720e-09])>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_fd_d2l_dx2 - o_d2l_dx2[:,part,dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400630bb",
   "metadata": {},
   "source": [
    "# Just the correlator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "683819b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = lambda x, s, i, training=False: tf.math.exp(w.correlator(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d56c2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Hamiltonian.compute_derivatives at 0x160b5db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "c_of_x, dc_dx, d2c_dx2 = h.compute_derivatives(c, xinputs, spins, isospins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6cb72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2; part=1\n",
    "fd_dc_dx, fd_d2c_dx2 = compute_numerical_derivatives(c, xinputs, spins, isospins, dim, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b750d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-1.37020617e-09, -6.43131895e-10, -9.71684150e-10])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc_dx[:,part,dim] - fd_dc_dx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18a72377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-2.82540900e-08,  1.42938258e-08,  1.92497839e-08])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2c_dx2[:,part,dim] - fd_d2c_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82a6e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the coordinates:\n",
    "c_of_x, dc_dx, d2c_dx2 = h.compute_derivatives(c, xinputs, spins, isospins)\n",
    "\n",
    "for dim in range(ndim):\n",
    "    for part in range(nparticles):\n",
    "        fd_dc_dx, fd_d2c_dx2 = compute_numerical_derivatives(c, xinputs, spins, isospins, dim, part) \n",
    "        assert (dc_dx[:,part,dim] - fd_dc_dx  < 1e-4).numpy().all()\n",
    "        assert (d2c_dx2[:,part,dim] - fd_d2c_dx2 < 1e-4).numpy().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2096a9b",
   "metadata": {},
   "source": [
    "## The correlator works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826cc842",
   "metadata": {},
   "source": [
    "# Just a single spatial net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "88578780",
   "metadata": {},
   "outputs": [],
   "source": [
    "sn = c = lambda x, s, i, training=False: w.spatial_nets[0](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0bcba8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 8 calls to <function Hamiltonian.compute_derivatives at 0x160b5db80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(\n",
      "[[[ 0.03046872]\n",
      "  [ 0.12013633]]\n",
      "\n",
      " [[-0.00304384]\n",
      "  [ 0.14237937]]\n",
      "\n",
      " [[ 0.06376086]\n",
      "  [ 0.09589538]]], shape=(3, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "sn_of_x, dsn_dx, d2sn_dx2 = h.compute_derivatives(sn, xinputs, spins, isospins)\n",
    "print(sn_of_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61cf0764",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2; part=1\n",
    "fd_dsn_dx, fd_d2sn_dx2 = compute_numerical_derivatives(sn, xinputs[:,part,:], spins, isospins, dim, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a979b888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([4.51136142e-11, 1.25718186e-11, 8.75603617e-11])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsn_dx[:,part,dim] - fd_dsn_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "53497294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-1.42281443e-08, -1.75155959e-08, -6.36823973e-09])>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2sn_dx2[:,part,dim] - fd_d2sn_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44a3374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all the coordinates:\n",
    "\n",
    "for net_index in range(nparticles):\n",
    "    sn = c = lambda x, s, i, training=False: w.spatial_nets[net_index](x)\n",
    "    sn_of_x, dsn_dx, d2sn_dx2 = h.compute_derivatives(sn, xinputs, spins, isospins)\n",
    "    for dim in range(ndim):\n",
    "        for part in range(nparticles):\n",
    "            fd_dsn_dx, fd_d2sn_dx2 = compute_numerical_derivatives(sn, xinputs[:,part,:], spins, isospins, dim, part)\n",
    "            assert(fd_dsn_dx.shape[0] == nwalkers)\n",
    "            assert (dsn_dx[:,part,dim] - fd_dsn_dx < 1e-4).numpy().all()\n",
    "            assert (d2sn_dx2[:,part,dim] - fd_d2sn_dx2 < 1e-4).numpy().all()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6616e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "print(fd_dsn_dx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcf541",
   "metadata": {},
   "source": [
    "## Both spatial nets works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99493c4",
   "metadata": {},
   "source": [
    "What about the vectorized spatial net implementation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b296fbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[ 0.03046872,  0.12013633],\n",
       "       [-0.00304384,  0.14237937],\n",
       "       [ 0.06376086,  0.09589538]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.compute_row(w.spatial_nets[0], xinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1f83689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[ 0.03046872,  0.12013633],\n",
       "       [-0.00304384,  0.14237937],\n",
       "       [ 0.06376086,  0.09589538]])>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(w.spatial_nets[0](xinputs), (nwalkers, nparticles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f4aad549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[-0.51251004,  0.48281624],\n",
       "       [-0.24184365,  0.18608135],\n",
       "       [-0.00431047, -0.04023421]])>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reshape(w.spatial_nets[1](xinputs), (nwalkers, nparticles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f18e4fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=float64, numpy=\n",
       "array([[[ 0.03046872,  0.12013633],\n",
       "        [-0.51251004,  0.48281624]],\n",
       "\n",
       "       [[-0.00304384,  0.14237937],\n",
       "        [-0.24184365,  0.18608135]],\n",
       "\n",
       "       [[ 0.06376086,  0.09589538],\n",
       "        [-0.00431047, -0.04023421]]])>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.compute_spatial_slater(xinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b66992f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 0.07628186,  0.03386714, -0.00215201])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.det(w.compute_spatial_slater(xinputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b81f2eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c665c5cd",
   "metadata": {},
   "source": [
    "# What about just the coordinate parts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef6d9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = lambda x, s, i, training=False: tf.linalg.det(w.compute_spatial_slater(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24e88820",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_of_x, o_dr_dx, o_d2r_dx2 = h.compute_derivatives(r, xinputs, spins, isospins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a88b821e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 0.07628186,  0.03386714, -0.00215201])>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1a7fac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2; part=0\n",
    "fd_dr_dx, fd_d2r_dx2 = compute_numerical_derivatives(r, xinputs, spins, isospins, dim, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f117de56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-3.20553251e-10, -6.32720015e-10, -4.65971040e-10])>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_dr_dx[:,part,dim] - fd_dr_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b516d028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ -0.24846157,   1.53342546, -15.29529662])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o_d2r_dx2[:,part,dim] - fd_d2r_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747dd4fa",
   "metadata": {},
   "source": [
    "# Isolating the 2nd derivative of the determinants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbea2e",
   "metadata": {},
   "source": [
    "It sure seems like the major issue is that the second derivative of a determinant is not working.  Let's demonstrate it with a simpler example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3035c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level function for each row:\n",
    "def f(this_input, _alpha):\n",
    "   return tf.exp(- tf.reduce_sum(_alpha * this_input**2, axis=(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b8adefde",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1 = lambda _i : f(_i, 11)\n",
    "net_2 = lambda _i : f(_i, 7.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "be101e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(_x, n1, n2):\n",
    "    row_1 = n1(_x) # Shape should be (nwalkers, nparticles)\n",
    "    row_2 = n2(_x)\n",
    "    matrix = tf.stack([row_1, row_2], axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "6e7ec3fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=float64, numpy=\n",
       "array([[[4.43496775e-01, 1.91415902e-04],\n",
       "        [5.78700139e-01, 3.15344463e-03]],\n",
       "\n",
       "       [[3.59072265e-03, 1.33788020e-06],\n",
       "        [2.26623092e-02, 1.11861510e-04]],\n",
       "\n",
       "       [[1.65738205e-03, 1.22184987e-03],\n",
       "        [1.34719285e-02, 1.09738106e-02]]])>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_matrix(inputs, net_1, net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "906acf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "detmat = lambda x, s=None, i=None, training=False : tf.linalg.det(compute_matrix(x, net_1, net_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "40fbd155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1.28777011e-03, 3.71344205e-07, 1.72712259e-06])>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9b5bbb3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 2])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(xinputs, 0.1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "02889a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1.28777011e-03, 3.71344205e-07, 1.72712259e-06])>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ef6b14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_of_x, , d2d_dx2 = h.compute_derivatives(detmat, inputs, spins, isospins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "46b27046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1.28777011e-03, 3.71344205e-07, 1.72712259e-06])>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5053d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim=0; part=0\n",
    "fd_dd_dx, fd_d2d_dx2 = compute_numerical_derivatives(detmat, inputs, spins, isospins, dim, part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "388d03f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([-3.21546831e-10,  9.34807664e-13,  7.32400504e-11])>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_dx[:,part, dim] - fd_dd_dx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a1f13cce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0.45036956, 0.02123967, 0.09771254])>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2d_dx2[:,part, dim] - fd_d2d_dx2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f77c08b",
   "metadata": {},
   "source": [
    "The second derivative is not matching.  But it can be computed numerically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54bf1c",
   "metadata": {},
   "source": [
    "# What about pytorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4aa8fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "84283962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level function for each row:\n",
    "def f_torch(this_input, _alpha):\n",
    "   return torch.exp(- torch.sum(_alpha * this_input**2, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bbd3eae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9926, 0.9251],\n",
       "        [0.9501, 0.8843],\n",
       "        [0.9435, 0.9408]], dtype=torch.float64)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_torch(torch.tensor(inputs), 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "9c0682cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float64, numpy=\n",
       "array([[0.99263575, 0.92512369],\n",
       "       [0.95011108, 0.88430849],\n",
       "       [0.94345681, 0.94084557]])>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(inputs, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4fb29331",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_1_torch = lambda _i : f_torch(_i, 11)\n",
    "net_2_torch = lambda _i : f_torch(_i, 7.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3d0defe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix_torch(_x, n1, n2):\n",
    "    row_1 = n1(_x) # Shape should be (nwalkers, nparticles)\n",
    "    row_2 = n2(_x)\n",
    "    matrix = torch.stack([row_1, row_2], axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "7c8ecda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.4350e-01, 1.9142e-04],\n",
       "         [5.7870e-01, 3.1534e-03]],\n",
       "\n",
       "        [[3.5907e-03, 1.3379e-06],\n",
       "         [2.2662e-02, 1.1186e-04]],\n",
       "\n",
       "        [[1.6574e-03, 1.2218e-03],\n",
       "         [1.3472e-02, 1.0974e-02]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_matrix_torch(torch.tensor(inputs), net_1_torch, net_2_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7cbdcb07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=float64, numpy=\n",
       "array([[[4.43496775e-01, 1.91415902e-04],\n",
       "        [5.78700139e-01, 3.15344463e-03]],\n",
       "\n",
       "       [[3.59072265e-03, 1.33788020e-06],\n",
       "        [2.26623092e-02, 1.11861510e-04]],\n",
       "\n",
       "       [[1.65738205e-03, 1.22184987e-03],\n",
       "        [1.34719285e-02, 1.09738106e-02]]])>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_matrix(inputs, net_1, net_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "26f3e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detmat_torch = lambda x, s=None, i=None, training=False : torch.linalg.det(compute_matrix_torch(x, net_1_torch, net_2_torch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "bc0f2cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_inputs = torch.tensor(inputs, requires_grad=True)\n",
    "output = detmat_torch(torch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a4d1025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2878e-03, 3.7134e-07, 1.7271e-06], dtype=torch.float64,\n",
       "       grad_fn=<LinalgDetBackward>)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "28ca7c4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/5dsy8_2x1wd93w36cdk7twz9s8nq7s/T/ipykernel_10501/4142703354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfirst_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mgrad_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "first_grad = torch.autograd.grad(output, torch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0d5f0d36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.1415e-03, -7.0255e-03, -1.8675e-03],\n",
       "         [-6.5121e-05, -1.4066e-02, -7.8540e-03]],\n",
       "\n",
       "        [[-5.0248e-06, -1.2191e-07, -3.2776e-06],\n",
       "         [-3.5667e-06, -4.5528e-06, -8.9185e-07]],\n",
       "\n",
       "        [[-1.1481e-04, -1.9242e-05, -2.6573e-05],\n",
       "         [ 6.4056e-05,  3.3989e-05,  3.2202e-06]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_inputs.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e673a213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=float64, numpy=\n",
       "array([[[-3.14152998e-03, -7.02550577e-03, -1.86753293e-03],\n",
       "        [-6.51206659e-05, -1.40659282e-02, -7.85402683e-03]],\n",
       "\n",
       "       [[-5.02479899e-06, -1.21913067e-07, -3.27755920e-06],\n",
       "        [-3.56668779e-06, -4.55284709e-06, -8.91848135e-07]],\n",
       "\n",
       "       [[-1.14811823e-04, -1.92416681e-05, -2.65727410e-05],\n",
       "        [ 6.40557560e-05,  3.39893400e-05,  3.22016415e-06]]])>"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b0296601",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Tensor returned by the function given to hessian should contain a single element",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/5dsy8_2x1wd93w36cdk7twz9s8nq7s/T/ipykernel_10501/1841685996.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetmat_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mhessian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tuple_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_inputs_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    484\u001b[0m                                               \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjac_func\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mjac_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_single_output_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         \u001b[0m_check_requires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jacobian\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_grad_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         is_outputs_tuple, outputs = _as_tuple(outputs,\n\u001b[1;32m    484\u001b[0m                                               \u001b[0;34m\"outputs of the user-provided function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SOFTWARE/larcv-env/lib/python3.8/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mensure_single_output_function\u001b[0;34m(*inp)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnelement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The Tensor returned by the function given to hessian should contain a single element\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Tensor returned by the function given to hessian should contain a single element"
     ]
    }
   ],
   "source": [
    "torch.autograd.functional.hessian(detmat_torch, torch_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142fe8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
