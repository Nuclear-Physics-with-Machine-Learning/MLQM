{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94562c7c",
   "metadata": {},
   "source": [
    "In tensorflow, the 2nd derivative of a matrix determinant does not match the numerical expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "DEFAULT_TENSOR_TYPE = \"float64\"\n",
    "\n",
    "nwalkers=1\n",
    "nparticles=2\n",
    "ndim=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_inputs(nwalkers, nparticles, ndim):\n",
    "\n",
    "    inputs = numpy.random.uniform(size=[nwalkers, nparticles, ndim])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46d7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = generate_inputs(nwalkers, nparticles, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00bb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b77ec63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level function for each row:\n",
    "class f:\n",
    "    def __init__(self, _alpha):\n",
    "        self.alpha = _alpha\n",
    "\n",
    "    def __call__(self, this_input):\n",
    "        return tf.exp(- tf.reduce_sum(self.alpha * this_input**2, axis=(2)))\n",
    "\n",
    "nets = []\n",
    "for i in range(nparticles):\n",
    "    val = numpy.random.random()\n",
    "    a = f(val)\n",
    "    nets.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98ca0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(inputs, _nets):\n",
    "    rows = [_n(inputs) for _n in _nets]\n",
    "    matrix = tf.stack(rows, axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb93de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[0.73954114, 0.71817769],\n",
       "        [0.67011944, 0.6445591 ]]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_matrix(inputs, nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b683897",
   "metadata": {},
   "outputs": [],
   "source": [
    "detmat = lambda x : tf.reshape(tf.linalg.det(compute_matrix(x, nets)), (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83bf52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-0.00458686]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a4e26",
   "metadata": {},
   "source": [
    "## Tensorflow computation of derivatives of a callable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cca74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def derivatives(w, inputs):\n",
    "\n",
    "        n_walkers = inputs.shape[0]\n",
    "        n_particles = inputs.shape[1]\n",
    "        n_dim = inputs.shape[2]\n",
    "        # Using the outer-most tape to watch the computation of the first derivative:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Use the inner tape to watch the computation of the wavefunction:\n",
    "            tape.watch(inputs)\n",
    "            with tf.GradientTape() as second_tape:\n",
    "                second_tape.watch(inputs)\n",
    "                w_of_x = w(inputs)\n",
    "                print(\"w_of_x: \", w_of_x)\n",
    "            # Get the derivative of logw_of_x with respect to inputs\n",
    "            dw_dx = second_tape.jacobian(w_of_x, inputs)\n",
    "            print(dw_dx.shape)\n",
    "            dw_dx = tf.reshape(dw_dx, (n_walkers, n_particles, n_dim))\n",
    "\n",
    "\n",
    "            \n",
    "        # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "        # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "        # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "        # The indexes represent partial derivative indexes, so,\n",
    "        # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "        # wavefunction at dimension d1\n",
    "\n",
    "        # This is the full hessian computation:\n",
    "        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "\n",
    "\n",
    "        \n",
    "        # Extract the diagonal parts:\n",
    "#         d2w_dx2 = tf.vectorized_map(tf.linalg.tensor_diag_part, d2w_dx2)\n",
    "#         print(d2w_dx2)\n",
    "\n",
    "        # # And this contracts:\n",
    "#         d2w_dx2 = tf.einsum(\"wpdpd->wpd\",d2w_dx2)\n",
    "        d2w_dx2 = tf.einsum(\"wpdpp->wpd\",d2w_dx2)\n",
    "#         print(d2w_dx2)\n",
    "        #\n",
    "        # print(\"First einsum: \", d2w_dx2[0])\n",
    "        #\n",
    "        # print(\"Method diff 0: \", d2w_dx2_t[0] - d2w_dx2[0])\n",
    "        # # TODO: test that the second derivative is correct with finite differences\n",
    "\n",
    "        return w_of_x, dw_dx, d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b4577a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_of_x:  Tensor(\"Reshape:0\", shape=(1, 1), dtype=float64)\n",
      "(1, 1, 1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "w_of_x, dw_dx, d2w_dx2 = derivatives(detmat, tf.convert_to_tensor(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5b94f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.20154997 -0.76812648]\n",
      "  [-0.19842823 -0.21865345]]], shape=(1, 2, 2), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(d2w_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a6a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eb2279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75244eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdd6b853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6959747e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[-0.00458686]])>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ba57317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[ 0.06203784,  0.1215111 ],\n",
       "        [-0.1307704 , -0.02676069]]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfedce03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[-0.20154997, -0.76812648],\n",
       "        [-0.19842823, -0.21865345]]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1145b",
   "metadata": {},
   "source": [
    "# Compare with numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f54c1fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivatives(f, x, dim, part, kick_size=1e-4):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    nparticles = x.shape[1]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape)\n",
    "    kick_size = 1e-4\n",
    "    \n",
    "    walkers = numpy.arange(nwalkers)\n",
    "\n",
    "    if len(kick.shape) == 3:\n",
    "        # Not single-particle\n",
    "        kick[walkers,part, dim] += kick_size\n",
    "    elif len(kick.shape) == 2:\n",
    "        # single particle:\n",
    "        kick[walkers, dim] += kick_size\n",
    "\n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x + 2*dx:\n",
    "#     kicked_double_up_input = x + \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x - 2*dx\n",
    "#     kicked_double_down_input = x - \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x)\n",
    "    w_up = f(kicked_up_input)\n",
    "    w_down = f(kicked_down_input)\n",
    "\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "#     w_prime_prime_num = -w_down_down + 16*w_down - 30* w_of_x + 16 * w_up - w_up_up\n",
    "    w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2a6e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2)\n",
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first = []\n",
    "second = []\n",
    "for dim in range(ndim):\n",
    "    first.append([])\n",
    "    second.append([])\n",
    "    for part in range(nparticles):\n",
    "\n",
    "        t_num_dw_dx, t_num_d2w_dx2 = numerical_derivatives(detmat, inputs, dim, part, kick_size=1e-6)\n",
    "        first[dim].append(t_num_dw_dx)\n",
    "        second[dim].append(t_num_d2w_dx2)\n",
    "    # At the end of the loop, the list should be length n_particles, with nwalker entries each.\n",
    "    # stack and flip it\n",
    "    first[-1] = numpy.stack(first[-1]).T\n",
    "    second[-1] = numpy.stack(second[-1]).T\n",
    "\n",
    "num_dw_dx = numpy.stack(first, axis=-1)\n",
    "num_d2w_dx2 = numpy.stack(second, axis=-1)\n",
    "print(num_dw_dx.shape)\n",
    "print(num_d2w_dx2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf08463e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2)\n",
      "(1, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(num_dw_dx.shape)\n",
    "print(num_d2w_dx2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c286792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.13617471 -0.01824917]\n",
      "  [ 0.0897577  -0.16683246]]]\n"
     ]
    }
   ],
   "source": [
    "print(num_d2w_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13daedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check against tensorflow derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "369b0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[-7.76148673e-10, -1.18106022e-09],\n",
       "        [ 1.14077892e-09,  3.66977032e-10]]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dw_dx - dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c097ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[0.33772468, 0.74987731],\n",
       "        [0.28818593, 0.05182099]]])>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d2w_dx2 - d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62440fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=float64, numpy=\n",
       "array([[[  2.48008372, -41.09104784],\n",
       "        [  3.21070986,  -0.31061697]]])>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2w_dx2 - d2w_dx2)/num_d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1e5c6",
   "metadata": {},
   "source": [
    "There is quite poor agreement in the second derivative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06991da6",
   "metadata": {},
   "source": [
    "## Even simpler case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404d76a",
   "metadata": {},
   "source": [
    "Let's create a matrix of just one variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ee39e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_inputs = tf.random.uniform((nwalkers,1), dtype=DEFAULT_TENSOR_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fc46c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_matrix:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = tf.random.uniform((1,2,2), dtype=DEFAULT_TENSOR_TYPE)\n",
    "        print(tf.reduce_sum(self.weights))\n",
    "        \n",
    "    def sm_base(self, x):\n",
    "        return tf.reshape(x**3, (-1, 1,1)) * self.weights\n",
    "    \n",
    "    def matrix_first_deriv(self,x):\n",
    "        return tf.reshape(3*x**2, (-1, 1, 1)) * self.weights\n",
    "            \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(tf.linalg.det(self.sm_base(x)), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5286fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2.1436791254445833, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "sm = simple_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9335748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.23931646]])>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17538703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_derivatives(w, inputs):\n",
    "\n",
    "    \n",
    "        # Using the outer-most tape to watch the computation of the first derivative:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Use the inner tape to watch the computation of the wavefunction:\n",
    "            tape.watch(inputs)\n",
    "            with tf.GradientTape() as second_tape:\n",
    "                second_tape.watch(inputs)\n",
    "                w_of_x = w(inputs)\n",
    "\n",
    "            # Get the derivative of logw_of_x with respect to inputs\n",
    "            dw_dx = second_tape.batch_jacobian(w_of_x, inputs)\n",
    "\n",
    "        # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "        # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "        # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "        # The indexes represent partial derivative indexes, so,\n",
    "        # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "        # wavefunction at dimension d1\n",
    "\n",
    "        # This is the full hessian computation:\n",
    "        print(\"dw_dx: \", dw_dx)\n",
    "        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "\n",
    "        print(\"d2w_dx2: \", d2w_dx2)\n",
    "        \n",
    "        # Extract the diagonal parts:\n",
    "#         d2w_dx2 = tf.linalg.tensor_diag_part(d2w_dx2)\n",
    "        \n",
    "#         print(tf.hessians(w_of_x, inputs))\n",
    "\n",
    "        # # And this contracts:\n",
    "        # d2w_dx2 = tf.einsum(\"wpdpd->wpd\",d2w_dx2)\n",
    "        #\n",
    "        # print(\"First einsum: \", d2w_dx2[0])\n",
    "        #\n",
    "        # print(\"Method diff 0: \", d2w_dx2_t[0] - d2w_dx2[0])\n",
    "        # # TODO: test that the second derivative is correct with finite differences\n",
    "\n",
    "        return w_of_x, tf.reshape(dw_dx, (-1,)), tf.reshape(d2w_dx2, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7998beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_numerical_derivatives(f, x, kick_size=1e-5):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape) + kick_size\n",
    "    \n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "    # x + 2*dx:\n",
    "    kicked_double_up_input = x + \\\n",
    "        tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "    # x - 2*dx\n",
    "    kicked_double_down_input = x - \\\n",
    "        tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x)\n",
    "    w_up = f(kicked_up_input)\n",
    "    w_down = f(kicked_down_input)\n",
    "    w_up_up = f(kicked_double_up_input)\n",
    "    w_down_down = f(kicked_double_down_input)\n",
    "\n",
    "    print(w_up)\n",
    "    print(w_down_down)\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "    w_prime_prime_num = -w_down_down + 16*w_down - 30* central_value + 16 * w_up - w_up_up\n",
    "    print(w_prime_prime_num)\n",
    "#     w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (12*kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ff52aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_dx:  tf.Tensor([[[1.58497546]]], shape=(1, 1, 1), dtype=float64)\n",
      "d2w_dx2:  tf.Tensor([[[[11.00703712]]]], shape=(1, 1, 1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "sm_of_x, dsm_dx, d2sm_dx2 = simple_derivatives(sm, simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3992df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float64, numpy=array([[0.23931646]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d33ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([1.58497546])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8820cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([11.00703712])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2sm_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0434e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.25561009]], shape=(1, 1), dtype=float64)\n",
      "tf.Tensor([[0.20931583]], shape=(1, 1), dtype=float64)\n",
      "tf.Tensor([[0.01049718]], shape=(1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "part=0; dim=0\n",
    "num_dsm_dx, num_d2sm_dx2 = simple_numerical_derivatives(sm, simple_inputs,kick_size=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfe4e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5856192])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3593ba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([0.00040616])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_dsm_dx - dsm_dx) / dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4fe5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.74764722])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d2sm_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15bf3347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([-2.25938989])>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2sm_dx2 - d2sm_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28ea3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float64, numpy=array([-0.25828544])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2sm_dx2 - d2sm_dx2) / num_d2sm_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafdf58",
   "metadata": {},
   "source": [
    "# Analytic Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ebeb8f",
   "metadata": {},
   "source": [
    "By Jacobi's formula, for a matrix A:\n",
    "\n",
    "$ \\frac{\\partial det(A)}{\\partial t} = det(A) tr[A^{-1} \\frac{\\partial A}{\\partial t }] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "842a9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_formula(A_callable, inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inputs)\n",
    "        matrix = A_callable.sm_base(inputs)\n",
    "    print(\"matrix.shape: \", matrix.shape)\n",
    "    inverse = tf.linalg.inv(matrix)\n",
    "    print(\"inverse: \", inverse)\n",
    "    print(inputs.shape)\n",
    "    partial = A_callable.matrix_first_deriv(inputs)\n",
    "    print(\"partial: \", partial)\n",
    "    partial = tape.batch_jacobian(matrix, inputs)\n",
    "    print(\"partial: \", partial)\n",
    "    product = tf.matmul(inverse, partial)\n",
    "    print(\"product: \", product)\n",
    "    \n",
    "    return tf.linalg.det(matrix) * tf.linalg.trace(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a01654ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix.shape:  (1, 2, 2)\n",
      "inverse:  tf.Tensor(\n",
      "[[[ 2.21883816 -0.22379812]\n",
      "  [-2.12051733  2.09710442]]], shape=(1, 2, 2), dtype=float64)\n",
      "(1, 1)\n",
      "partial:  tf.Tensor(\n",
      "[[[1.66192952 0.17735726]\n",
      "  [1.68048396 1.75840201]]], shape=(1, 2, 2), dtype=float64)\n",
      "partial:  tf.Tensor(\n",
      "[[[[1.66192952]\n",
      "   [0.17735726]]\n",
      "\n",
      "  [[1.68048396]\n",
      "   [1.75840201]]]], shape=(1, 2, 2, 1), dtype=float64)\n",
      "product:  tf.Tensor(\n",
      "[[[[ 3.64786042]\n",
      "   [-3.15221364]]\n",
      "\n",
      "  [[ 3.33519487]\n",
      "   [ 0.1240573 ]]]], shape=(1, 2, 2, 1), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float64, numpy=array([[0.87299305, 0.79816704]])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobi_formula(sm, simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bfe017a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.58497546], shape=(1,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(dsm_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a561b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
