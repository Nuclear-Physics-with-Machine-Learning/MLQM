{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94562c7c",
   "metadata": {},
   "source": [
    "In tensorflow, the 2nd derivative of a matrix determinant does not match the numerical expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "498ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "DEFAULT_TENSOR_TYPE = \"float64\"\n",
    "\n",
    "nwalkers=2\n",
    "nparticles=2\n",
    "ndim=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "841e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_inputs(nwalkers, nparticles, ndim):\n",
    "\n",
    "    inputs = numpy.random.uniform(size=[nwalkers, nparticles, ndim])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a46d7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = generate_inputs(nwalkers, nparticles, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c00bb35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b77ec63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level function for each row:\n",
    "class f:\n",
    "    def __init__(self, _alpha):\n",
    "        self.alpha = _alpha\n",
    "\n",
    "    def __call__(self, this_input):\n",
    "        '''\n",
    "        this is computed e^-alpha[x^2 + y^2 + z^2]\n",
    "        '''\n",
    "        return tf.exp(- tf.reduce_sum(self.alpha * this_input**2, axis=(2)))\n",
    "\n",
    "nets = []\n",
    "for i in range(nparticles):\n",
    "    val = numpy.random.random()\n",
    "    a = f(val)\n",
    "    nets.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "98ca0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matrix(inputs, _nets):\n",
    "    rows = [_n(inputs) for _n in _nets]\n",
    "    matrix = tf.stack(rows, axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bb93de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float64, numpy=\n",
       "array([[[0.69038104, 0.98185776],\n",
       "        [0.63837003, 0.97806487]],\n",
       "\n",
       "       [[0.87714892, 0.98081428],\n",
       "        [0.85317696, 0.97680581]]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_matrix(inputs, nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8f869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b683897",
   "metadata": {},
   "outputs": [],
   "source": [
    "detmat = lambda x : tf.reshape(tf.linalg.det(compute_matrix(x, nets)), (-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "83bf52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[0.04844887],\n",
       "       [0.01999602]])>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc24b1",
   "metadata": {},
   "source": [
    "## Numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2636a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivatives(f, x, dim, part, kick_size=1e-4):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    nparticles = x.shape[1]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape)\n",
    "    kick_size = 1e-4\n",
    "    \n",
    "    walkers = numpy.arange(nwalkers)\n",
    "\n",
    "    if len(kick.shape) == 3:\n",
    "        # Not single-particle\n",
    "        kick[walkers,part, dim] += kick_size\n",
    "    elif len(kick.shape) == 2:\n",
    "        # single particle:\n",
    "        kick[walkers, dim] += kick_size\n",
    "\n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x + 2*dx:\n",
    "#     kicked_double_up_input = x + \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x - 2*dx\n",
    "#     kicked_double_down_input = x - \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x)\n",
    "    w_up = f(kicked_up_input)\n",
    "    w_down = f(kicked_down_input)\n",
    "\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "#     w_prime_prime_num = -w_down_down + 16*w_down - 30* w_of_x + 16 * w_up - w_up_up\n",
    "    w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0d0d1cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1)\n",
      "(2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "first = []\n",
    "second = []\n",
    "for dim in range(ndim):\n",
    "    first.append([])\n",
    "    second.append([])\n",
    "    for part in range(nparticles):\n",
    "\n",
    "        t_num_dw_dx, t_num_d2w_dx2 = numerical_derivatives(detmat, inputs, dim, part, kick_size=1e-6)\n",
    "        first[dim].append(t_num_dw_dx)\n",
    "        second[dim].append(t_num_d2w_dx2)\n",
    "    # At the end of the loop, the list should be length n_particles, with nwalker entries each.\n",
    "    # stack and flip it\n",
    "    first[-1] = numpy.stack(first[-1]).T\n",
    "    second[-1] = numpy.stack(second[-1]).T\n",
    "\n",
    "num_dw_dx = numpy.stack(first, axis=-1)\n",
    "num_d2w_dx2 = numpy.stack(second, axis=-1)\n",
    "print(num_dw_dx.shape)\n",
    "print(num_d2w_dx2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a4e26",
   "metadata": {},
   "source": [
    "## Tensorflow computation of derivatives of a callable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3cca74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivatives(w, inputs):\n",
    "\n",
    "        n_walkers = inputs.shape[0]\n",
    "        n_particles = inputs.shape[1]\n",
    "        n_dim = inputs.shape[2]\n",
    "        # Using the outer-most tape to watch the computation of the first derivative:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Use the inner tape to watch the computation of the wavefunction:\n",
    "            tape.watch(inputs)\n",
    "            with tf.GradientTape() as second_tape:\n",
    "                second_tape.watch(inputs)\n",
    "                w_of_x = w(inputs)\n",
    "                print(\"w_of_x: \", w_of_x)\n",
    "            # Get the derivative of logw_of_x with respect to inputs\n",
    "            dw_dx = second_tape.gradient(w_of_x, inputs)\n",
    "#             dw_dx = second_tape.batch_jacobian(w_of_x, inputs)\n",
    "            print(dw_dx)\n",
    "            dw_dx = tf.reshape(dw_dx, (n_walkers, n_particles, n_dim))\n",
    "\n",
    "\n",
    "            \n",
    "        # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "        # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "        # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "        # The indexes represent partial derivative indexes, so,\n",
    "        # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "        # wavefunction at dimension d1\n",
    "\n",
    "        # This is the full hessian computation:\n",
    "        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "        print(d2w_dx2)\n",
    "\n",
    "        \n",
    "        # Extract the diagonal parts:\n",
    "        d2w_dx2 = tf.vectorized_map(tf.linalg.tensor_diag_part, d2w_dx2)\n",
    "        print(d2w_dx2)\n",
    "\n",
    "        # # And this contracts:\n",
    "#         d2w_dx2 = tf.einsum(\"wpdpd->wpd\",d2w_dx2)\n",
    "#         d2w_dx2 = tf.einsum(\"wpdpp->wpd\",d2w_dx2)\n",
    "#         print(d2w_dx2)\n",
    "        #\n",
    "        # print(\"First einsum: \", d2w_dx2[0])\n",
    "        #\n",
    "        # print(\"Method diff 0: \", d2w_dx2_t[0] - d2w_dx2[0])\n",
    "        # # TODO: test that the second derivative is correct with finite differences\n",
    "\n",
    "        return w_of_x, dw_dx, d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8b4577a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_of_x:  tf.Tensor(\n",
      "[[0.04844887]\n",
      " [0.01999602]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[ 0.07607763]\n",
      "  [-0.03846837]]\n",
      "\n",
      " [[ 0.08446972]\n",
      "  [-0.04162483]]], shape=(2, 2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[[[-0.21982436]\n",
      "    [ 0.04240996]]]\n",
      "\n",
      "\n",
      "  [[[-0.04193168]\n",
      "    [-0.18177932]]]]\n",
      "\n",
      "\n",
      "\n",
      " [[[[ 0.05629544]\n",
      "    [ 0.00619567]]]\n",
      "\n",
      "\n",
      "  [[[-0.03219107]\n",
      "    [-0.19160706]]]]], shape=(2, 2, 1, 2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[[-0.21982436]\n",
      "  [-0.18177932]]\n",
      "\n",
      " [[ 0.05629544]\n",
      "  [-0.19160706]]], shape=(2, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "w_of_x, dw_dx, d2w_dx2 = derivatives(detmat, tf.convert_to_tensor(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5b94f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.21982436]\n",
      "  [-0.18177932]]\n",
      "\n",
      " [[ 0.05629544]\n",
      "  [-0.19160706]]], shape=(2, 2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(d2w_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a28a6a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.1074315 ]\n",
      "  [-0.19663074]]\n",
      "\n",
      " [[ 0.06588023]\n",
      "  [-0.20433577]]]\n"
     ]
    }
   ],
   "source": [
    "print(num_d2w_dx2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1145b",
   "metadata": {},
   "source": [
    "# Compare with numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0c286792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.1074315 ]\n",
      "  [-0.19663074]]\n",
      "\n",
      " [[ 0.06588023]\n",
      "  [-0.20433577]]]\n"
     ]
    }
   ],
   "source": [
    "print(num_d2w_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "13daedf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check against tensorflow derivatives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "369b0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=float64, numpy=\n",
       "array([[[-6.81367129e-10],\n",
       "        [ 3.97317346e-10]],\n",
       "\n",
       "       [[-9.40860945e-10],\n",
       "        [ 4.70982919e-10]]])>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dw_dx - dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c097ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=float64, numpy=\n",
       "array([[[ 0.11239286],\n",
       "        [-0.01485143]],\n",
       "\n",
       "       [[ 0.00958479],\n",
       "        [-0.01272871]]])>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d2w_dx2 - d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62440fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=float64, numpy=\n",
       "array([[[-1.04618157],\n",
       "        [ 0.07552952]],\n",
       "\n",
       "       [[ 0.14548808],\n",
       "        [ 0.06229312]]])>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2w_dx2 - d2w_dx2)/num_d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1e5c6",
   "metadata": {},
   "source": [
    "There is quite poor agreement in the second derivative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06991da6",
   "metadata": {},
   "source": [
    "## Even simpler case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404d76a",
   "metadata": {},
   "source": [
    "Let's create a matrix of just one variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ee39e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_inputs = tf.random.uniform((nwalkers,1), dtype=DEFAULT_TENSOR_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fc46c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_matrix:\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.weights = tf.random.uniform((1,2,2), dtype=DEFAULT_TENSOR_TYPE)\n",
    "        print(tf.reduce_sum(self.weights))\n",
    "        \n",
    "    def sm_base(self, x):\n",
    "        return tf.reshape(x**3, (-1, 1,1)) * self.weights\n",
    "    \n",
    "    def matrix_first_deriv(self,x):\n",
    "        return tf.reshape(3*x**2, (-1, 1, 1)) * self.weights\n",
    "            \n",
    "    \n",
    "    def __call__(self, x):\n",
    "        return tf.reshape(tf.linalg.det(self.sm_base(x)), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5286fbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.2871075918646473, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "sm = simple_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9335748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[3.12273893e-02],\n",
       "       [8.53440729e-10]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17538703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_derivatives(w, inputs):\n",
    "\n",
    "    \n",
    "        # Using the outer-most tape to watch the computation of the first derivative:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Use the inner tape to watch the computation of the wavefunction:\n",
    "            tape.watch(inputs)\n",
    "            with tf.GradientTape() as second_tape:\n",
    "                second_tape.watch(inputs)\n",
    "                w_of_x = w(inputs)\n",
    "\n",
    "            # Get the derivative of logw_of_x with respect to inputs\n",
    "            dw_dx = second_tape.batch_jacobian(w_of_x, inputs)\n",
    "\n",
    "        # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "        # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "        # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "        # The indexes represent partial derivative indexes, so,\n",
    "        # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "        # wavefunction at dimension d1\n",
    "\n",
    "        # This is the full hessian computation:\n",
    "        print(\"dw_dx: \", dw_dx)\n",
    "        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "\n",
    "        print(\"d2w_dx2: \", d2w_dx2)\n",
    "        \n",
    "        # Extract the diagonal parts:\n",
    "#         d2w_dx2 = tf.linalg.tensor_diag_part(d2w_dx2)\n",
    "        \n",
    "#         print(tf.hessians(w_of_x, inputs))\n",
    "\n",
    "        # # And this contracts:\n",
    "        # d2w_dx2 = tf.einsum(\"wpdpd->wpd\",d2w_dx2)\n",
    "        #\n",
    "        # print(\"First einsum: \", d2w_dx2[0])\n",
    "        #\n",
    "        # print(\"Method diff 0: \", d2w_dx2_t[0] - d2w_dx2[0])\n",
    "        # # TODO: test that the second derivative is correct with finite differences\n",
    "\n",
    "        return w_of_x, tf.reshape(dw_dx, (-1,)), tf.reshape(d2w_dx2, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7998beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_numerical_derivatives(f, x, kick_size=1e-5):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape) + kick_size\n",
    "    \n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "    # x + 2*dx:\n",
    "    kicked_double_up_input = x + \\\n",
    "        tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "    # x - 2*dx\n",
    "    kicked_double_down_input = x - \\\n",
    "        tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x)\n",
    "    w_up = f(kicked_up_input)\n",
    "    w_down = f(kicked_down_input)\n",
    "    w_up_up = f(kicked_double_up_input)\n",
    "    w_down_down = f(kicked_double_down_input)\n",
    "\n",
    "    print(w_up)\n",
    "    print(w_down_down)\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "    w_prime_prime_num = -w_down_down + 16*w_down - 30* central_value + 16 * w_up - w_up_up\n",
    "    print(w_prime_prime_num)\n",
    "#     w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (12*kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ff52aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw_dx:  tf.Tensor(\n",
      "[[[2.28819143e-01]]\n",
      "\n",
      " [[1.13943729e-07]]], shape=(2, 1, 1), dtype=float64)\n",
      "d2w_dx2:  tf.Tensor(\n",
      "[[[[1.41672353e+00]]]\n",
      "\n",
      "\n",
      " [[[1.28541560e-05]]]], shape=(2, 1, 1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "sm_of_x, dsm_dx, d2sm_dx2 = simple_derivatives(sm, simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3992df72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[3.12273893e-02],\n",
       "       [8.53440729e-10]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm_of_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d33ff0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([2.28819143e-01, 1.13943729e-07])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8820cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([1.41672353e+00, 1.28541560e-05])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2sm_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0434e6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.35865902e-02]\n",
      " [2.84908670e-09]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[2.69215168e-02]\n",
      " [2.49321101e-11]], shape=(2, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[1.67667555e-03]\n",
      " [1.52027959e-08]], shape=(2, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "part=0; dim=0\n",
    "num_dsm_dx, num_d2sm_dx2 = simple_numerical_derivatives(sm, simple_inputs,kick_size=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfe4e80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.28932906e-01, 1.33029271e-07])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3593ba5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([0.00049717, 0.16749972])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_dsm_dx - dsm_dx) / dsm_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4fe5b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.39722962e+00, 1.26689966e-05])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_d2sm_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "15bf3347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([-1.94939106e-02, -1.85159411e-07])>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2sm_dx2 - d2sm_dx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28ea3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([-0.01395183, -0.01461516])>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(num_d2sm_dx2 - d2sm_dx2) / num_d2sm_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaafdf58",
   "metadata": {},
   "source": [
    "# Analytic Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ebeb8f",
   "metadata": {},
   "source": [
    "By Jacobi's formula, for a matrix A:\n",
    "\n",
    "$ \\frac{\\partial det(A)}{\\partial t} = det(A) tr[A^{-1} \\frac{\\partial A}{\\partial t }] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "842a9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_formula(A_callable, inputs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inputs)\n",
    "        matrix = A_callable.sm_base(inputs)\n",
    "    print(\"matrix.shape: \", matrix.shape)\n",
    "    inverse = tf.linalg.inv(matrix)\n",
    "    print(\"inverse: \", inverse)\n",
    "    print(inputs.shape)\n",
    "    partial = A_callable.matrix_first_deriv(inputs)\n",
    "    print(\"partial: \", partial)\n",
    "    partial = tape.batch_jacobian(matrix, inputs)\n",
    "    print(\"partial: \", partial)\n",
    "    product = tf.matmul(inverse, partial)\n",
    "    print(\"product: \", product)\n",
    "    \n",
    "    return tf.linalg.det(matrix) * tf.linalg.trace(product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a01654ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix.shape:  (2, 2, 2)\n",
      "inverse:  tf.Tensor(\n",
      "[[[ 3.56109784e+00 -2.82391986e+00]\n",
      "  [-4.04427724e+00  1.21995764e+01]]\n",
      "\n",
      " [[ 2.15409604e+04 -1.70817957e+04]\n",
      "  [-2.44636962e+04  7.37948248e+04]]], shape=(2, 2, 2), dtype=float64)\n",
      "(2, 1)\n",
      "partial:  tf.Tensor(\n",
      "[[[1.39574830e+00 3.23083461e-01]\n",
      "  [4.62704027e-01 4.07423678e-01]]\n",
      "\n",
      " [[4.20422875e-03 9.73181750e-04]\n",
      "  [1.39374239e-03 1.22722867e-03]]], shape=(2, 2, 2), dtype=float64)\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x163787af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "partial:  tf.Tensor(\n",
      "[[[[1.39574830e+00]\n",
      "   [3.23083461e-01]]\n",
      "\n",
      "  [[4.62704027e-01]\n",
      "   [4.07423678e-01]]]\n",
      "\n",
      "\n",
      " [[[4.20422875e-03]\n",
      "   [9.73181750e-04]]\n",
      "\n",
      "  [[1.39374239e-03]\n",
      "   [1.22722867e-03]]]], shape=(2, 2, 2, 1), dtype=float64)\n",
      "product:  tf.Tensor(\n",
      "[[[[ 4.05803446e+00]\n",
      "   [-1.70331175e+00]]\n",
      "\n",
      "  [[ 3.00756106e+03]\n",
      "   [ 1.87463081e+04]]]\n",
      "\n",
      "\n",
      " [[[ 1.22234826e-02]\n",
      "   [-5.13066160e-03]]\n",
      "\n",
      "  [[ 9.05928001e+00]\n",
      "   [ 5.64670346e+01]]]], shape=(2, 2, 2, 1), dtype=float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float64, numpy=\n",
       "array([[1.26721822e-01, 2.56677511e-06],\n",
       "       [3.81707451e-04, 7.73155853e-09]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jacobi_formula(sm, simple_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfe017a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2.28819143e-01 1.13943729e-07], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(dsm_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4a561b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
