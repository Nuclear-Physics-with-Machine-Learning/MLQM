{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94562c7c",
   "metadata": {},
   "source": [
    "### In tensorflow, the 2nd derivative of a matrix determinant does not match the numerical expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498ecb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "DEFAULT_TENSOR_TYPE = \"float64\"\n",
    "\n",
    "nwalkers=2\n",
    "nparticles=3\n",
    "ndim=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "841e3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random inputs as needed, of the right shape/\n",
    "def generate_inputs(nwalkers, nparticles, ndim):\n",
    "\n",
    "    inputs = numpy.random.uniform(size=[nwalkers, nparticles, ndim])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46d7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = generate_inputs(nwalkers, nparticles, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c00bb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38c94f",
   "metadata": {},
   "source": [
    "### What is the function doing?\n",
    "\n",
    "The \"real\" case is a function that forms a matrix by applying n_particle Neural Networks to n_particle individual inputs.  Each Neural Network R operates on a single particle of arbitrary number of dimensions, though 3 is the most interesting case.  The total input is of shape $(N, N_{particles}, N_{dim})$, and we have R_{N_{particles}} neural networks.  the matrix is then formed as:\n",
    "\n",
    "$\n",
    "R_0(x_0) ~ R_0(x_1) ~  ... ~ R_0(x_n) \\\\\n",
    "R_1(x_0) ~ R_1(x_1) ~  ... ~ R_N(x_n) \\\\\n",
    ". \\\\ \n",
    ". \\\\ \n",
    ". \\\\\n",
    "R_N(x_0) ~ R_N(x_1) ~  ... ~ R_N(x_n) \\\\\n",
    "$\n",
    "\n",
    "The total function is a scalar: the determinant of this matrix.\n",
    "\n",
    "In this notebook, for simplicity, instead of a neural network we're just using gaussian functions with one parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77ec63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-level function for each row:\n",
    "class f:\n",
    "    def __init__(self, _alpha):\n",
    "        self.alpha = _alpha\n",
    "\n",
    "    def __call__(self, this_input):\n",
    "        '''\n",
    "        this is computed e^-alpha[x^2 + y^2 + z^2]\n",
    "        '''\n",
    "        return tf.exp(- tf.reduce_sum(self.alpha * this_input**2, axis=(2)))\n",
    "\n",
    "nets = []\n",
    "for i in range(nparticles):\n",
    "    val = numpy.random.random()\n",
    "    a = f(val)\n",
    "    nets.append(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ca0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this applies each \"network\" (actually a guassian in this notebook) to each particle, and stacks them into a matrix\n",
    "def compute_matrix(inputs, _nets):\n",
    "    rows = [_n(inputs) for _n in _nets]\n",
    "    matrix = tf.stack(rows, axis=1)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb93de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.83233935 0.37374074 0.22569332]\n",
      "  [0.75848975 0.22707492 0.10622208]\n",
      "  [0.78409486 0.27133    0.13905074]]\n",
      "\n",
      " [[0.42416383 0.86898265 0.38830493]\n",
      "  [0.27476374 0.80934434 0.24053442]\n",
      "  [0.32088127 0.83017026 0.28543172]]], shape=(2, 3, 3), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "matrix = compute_matrix(inputs, nets)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5a8f869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[0.83233935, 0.37374074, 0.22569332],\n",
       "       [0.42416383, 0.86898265, 0.38830493]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nets[0](inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b683897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are two functions that compute scalar values from this matrix.\n",
    "\n",
    "# The determinant, as mentioned:\n",
    "detmat = lambda x : tf.reshape(tf.linalg.det(compute_matrix(x, nets)), (-1,1))\n",
    "\n",
    "# Same as above but calling a different TF function\n",
    "def logdetmat(x):\n",
    "    s, ld = tf.linalg.slogdet(compute_matrix(x, nets))\n",
    "    return tf.reshape( s * tf.exp(ld), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a318fbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_matrix(batch_matrix, row, column):\n",
    "    left = batch_matrix[:,0:row,:]\n",
    "    right = batch_matrix[:,row+1:,:]\n",
    "    row_removed = tf.concat((left, right), axis=1)\n",
    "    top = row_removed[:,:,0:column]\n",
    "    bottom = row_removed[:,:,column+1:]\n",
    "    return tf.concat((top, bottom), axis=2)\n",
    "\n",
    "def custom_determinant(_matrix):\n",
    "\n",
    "#     print(\"Entering\")\n",
    "#     print(_matrix)\n",
    "    \n",
    "    # Here is a custom, maybe slower, determinant implementation.\n",
    "    # It operates over the batch size\n",
    "    \n",
    "    # The matrix should be a size [N, m, m] where N is the batch size.\n",
    "        \n",
    "    assert (_matrix.shape[1] == _matrix.shape[2])\n",
    "    \n",
    "    # Implementing this recursively, so start with the base case:\n",
    "    \n",
    "    if _matrix.shape[1] == 1: \n",
    "#         print(\"base case!\")\n",
    "        return tf.reshape(_matrix, (-1))\n",
    "    else:\n",
    "        # Need to get the submatrixes:\n",
    "        sign = 1.0\n",
    "        det  = 0.0\n",
    "        for i in range(_matrix.shape[1]):\n",
    "            sm = sub_matrix(_matrix, row=0, column=i)\n",
    "#             print(\"sm: \", sm)\n",
    "#             print(\"_matrix[:,i, 0]:\", _matrix[:,0,i])\n",
    "            sub_det = sign *_matrix[:,0,i]*custom_determinant(sm)\n",
    "#             print(\"sub_det: \", sub_det)\n",
    "            contribution =  sub_det\n",
    "#             print(\"contribution: \", contribution)\n",
    "            det += contribution\n",
    "            sign *= -1.\n",
    "        \n",
    "        return det\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b89b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256437b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([ 2.65912086e-04, -6.36939195e-05])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_determinant(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7b8a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([ 2.65912086e-04, -6.36939195e-05])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd1b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The custom determinant:\n",
    "detmat_custom = lambda x : tf.reshape(custom_determinant(compute_matrix(x, nets)), (-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83bf52bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ 2.65912086e-04],\n",
       "       [-6.36939195e-05]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c85fa6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ 2.65912086e-04],\n",
       "       [-6.36939195e-05]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detmat_custom(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64034e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
       "array([[ 2.65912086e-04],\n",
       "       [-6.36939195e-05]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdetmat(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa0e291",
   "metadata": {},
   "source": [
    "#### Everything is in agreement in value for all three functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76ce29a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([ 2.65912086e-04, -6.36939195e-05])>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_determinant(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d657b78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float64, numpy=array([ 2.65912086e-04, -6.36939195e-05])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.det(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "617c3247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 2.65912086e-04 -6.36939195e-05], shape=(2,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "s, ld  = tf.linalg.slogdet(matrix)\n",
    "print(s*tf.exp(ld))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc24b1",
   "metadata": {},
   "source": [
    "## Numerical differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2636a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_derivatives(f, x, dim, part, kick_size=1e-4):\n",
    "    # Get the shapes:\n",
    "    nwalkers = x.shape[0]\n",
    "    nparticles = x.shape[1]\n",
    "    # Placeholder for a kick:\n",
    "    kick = numpy.zeros(shape = x.shape)\n",
    "    kick_size = 1e-4\n",
    "    \n",
    "    walkers = numpy.arange(nwalkers)\n",
    "\n",
    "    if len(kick.shape) == 3:\n",
    "        # Not single-particle\n",
    "        kick[walkers,part, dim] += kick_size\n",
    "    elif len(kick.shape) == 2:\n",
    "        # single particle:\n",
    "        kick[walkers, dim] += kick_size\n",
    "\n",
    "#     print(kick)\n",
    "    \n",
    "    # x + dx:\n",
    "    kicked_up_input = x + \\\n",
    "            tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x + 2*dx:\n",
    "#     kicked_double_up_input = x + \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    # x - dx\n",
    "    kicked_down_input = x - \\\n",
    "        tf.convert_to_tensor(kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "\n",
    "#     # x - 2*dx\n",
    "#     kicked_double_down_input = x - \\\n",
    "#         tf.convert_to_tensor(2*kick, dtype=DEFAULT_TENSOR_TYPE)\n",
    "    \n",
    "    central_value = f(x)\n",
    "    w_up = f(kicked_up_input)\n",
    "    w_down = f(kicked_down_input)\n",
    "\n",
    "    \n",
    "    # Use numpy to make slicing easier\n",
    "    w_prime_fd = tf.reshape((w_up - w_down) / (2*kick_size), (nwalkers,)).numpy()\n",
    "    # What about the second derivative?\n",
    "\n",
    "    # https://math.stackexchange.com/questions/3756717/finite-differences-second-derivative-as-successive-application-of-the-first-deri\n",
    "    # This gives precision of O(kick**4)\n",
    "#     w_prime_prime_num = -w_down_down + 16*w_down - 30* w_of_x + 16 * w_up - w_up_up\n",
    "    w_prime_prime_num = w_up + w_down - 2*central_value\n",
    "    w_prime_prime_fd = tf.reshape(w_prime_prime_num/ (kick_size**2), (nwalkers,)).numpy()\n",
    "\n",
    "    return w_prime_fd, w_prime_prime_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d0d1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_numerical_derivatives(f, ndim, nparticles, kick_size=1e-6):\n",
    "    first = []\n",
    "    second = []\n",
    "    for dim in range(ndim):\n",
    "        first.append([])\n",
    "        second.append([])\n",
    "        for part in range(nparticles):\n",
    "\n",
    "            t_num_dw_dx, t_num_d2w_dx2 = numerical_derivatives(f, inputs, dim, part, kick_size)\n",
    "            first[dim].append(t_num_dw_dx)\n",
    "            second[dim].append(t_num_d2w_dx2)\n",
    "        # At the end of the loop, the list should be length n_particles, with nwalker entries each.\n",
    "        # stack and flip it\n",
    "        first[-1] = numpy.stack(first[-1]).T\n",
    "        second[-1] = numpy.stack(second[-1]).T\n",
    "\n",
    "    num_dw_dx = numpy.stack(first, axis=-1)\n",
    "    num_d2w_dx2 = numpy.stack(second, axis=-1)\n",
    "    \n",
    "    return num_dw_dx, num_d2w_dx2\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6a4e26",
   "metadata": {},
   "source": [
    "## Tensorflow computation of derivatives of a callable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cca74d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivatives(w, inputs):\n",
    "\n",
    "        n_walkers = inputs.shape[0]\n",
    "        n_particles = inputs.shape[1]\n",
    "        n_dim = inputs.shape[2]\n",
    "        # Using the outer-most tape to watch the computation of the first derivative:\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Use the inner tape to watch the computation of the wavefunction:\n",
    "            tape.watch(inputs)\n",
    "            with tf.GradientTape() as second_tape:\n",
    "                second_tape.watch(inputs)\n",
    "                w_of_x = w(inputs)\n",
    "            # Get the derivative of logw_of_x with respect to inputs\n",
    "            dw_dx = second_tape.gradient(w_of_x, inputs)\n",
    "\n",
    "            \n",
    "        # Get the derivative of dlogw_dx with respect to inputs (aka second derivative)\n",
    "\n",
    "        # We have to extract the diagonal of the jacobian, which comes out with shape\n",
    "        # [nwalkers, nparticles, dimension, nwalkers, nparticles, dimension]\n",
    "\n",
    "        # The indexes represent partial derivative indexes, so,\n",
    "        # d2w_dx2[i_w, n1,d1, n2, d2] represents the second derivative of the\n",
    "        # wavefunction at dimension d1\n",
    "\n",
    "        # This is the full hessian computation:\n",
    "        d2w_dx2 = tape.batch_jacobian(dw_dx, inputs)\n",
    "        d2w_dx2 = tf.reshape(d2w_dx2, (n_walkers, n_particles*n_dim, n_particles*n_dim))\n",
    "\n",
    "        \n",
    "        # Extract the diagonal parts:\n",
    "        d2w_dx2 = tf.vectorized_map(tf.linalg.tensor_diag_part, d2w_dx2)\n",
    "\n",
    "        d2w_dx2 = tf.reshape(d2w_dx2, (-1, n_particles, n_dim))\n",
    "        \n",
    "        return w_of_x, dw_dx, d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa512640",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_of_x, dw_dx, d2w_dx2 = derivatives(logdetmat, tf.convert_to_tensor(inputs))\n",
    "num_dw_dx, num_d2w_dx2 = full_numerical_derivatives(logdetmat, ndim, nparticles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1145b",
   "metadata": {},
   "source": [
    "# Compare with numerical derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "369b0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 7.16275390e-12,  2.24241502e-12,  2.94030425e-12],\n",
       "        [-3.08143268e-13,  2.70320875e-12,  8.63188427e-12],\n",
       "        [-3.78174618e-12, -5.05935658e-12, -4.85289109e-12]],\n",
       "\n",
       "       [[-2.93745974e-12, -7.13880268e-12, -1.72663641e-13],\n",
       "        [-1.79237593e-12, -1.06337237e-12, -1.58892691e-12],\n",
       "        [ 5.93439859e-12,  8.38320982e-12,  5.81487332e-13]]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error in the first derivative using the tf determinant, should be < 1e-6 (kick_size)\n",
    "num_dw_dx - dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c097ab4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[-2.12144931e-03, -1.26565997e-04, -2.24313538e-04],\n",
       "        [ 7.94129972e-05,  3.33812677e-03,  5.88275189e-03],\n",
       "        [ 1.25819290e-03,  2.18056172e-03,  2.01692124e-03]],\n",
       "\n",
       "       [[ 5.33798062e-03,  8.45565487e-03,  2.21704051e-03],\n",
       "        [-4.88294903e-03, -1.45538992e-03, -3.61198767e-03],\n",
       "        [ 2.07485070e-02,  2.65361960e-02,  2.76021238e-03]]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error in the first derivative using the tf determinant, should be < 1e-6 (kick_size)\n",
    "num_d2w_dx2 - d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62440fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 11.6418252 ,   0.11927465,   0.2203331 ],\n",
       "        [ -0.11550726,  -3.2609662 ,  -4.57393179],\n",
       "        [-35.28364784,  -5.083045  ,  -5.6149554 ]],\n",
       "\n",
       "       [[  4.7568459 ,   6.77625287,   2.2251186 ],\n",
       "        [-26.4377604 ,  -5.23644349, -16.47281571],\n",
       "        [-26.85381152, -36.19497695,  -3.08260865]]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the relative error in the second derivative using the custom operation:\n",
    "(num_d2w_dx2 - d2w_dx2)/num_d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1e5c6",
   "metadata": {},
   "source": [
    "### There is quite poor agreement in the second derivative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce80358",
   "metadata": {},
   "source": [
    "## Derivatives with custom determinant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dce303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_w_of_x, c_dw_dx, c_d2w_dx2 = derivatives(detmat_custom, tf.convert_to_tensor(inputs))\n",
    "c_num_dw_dx, c_num_d2w_dx2 = full_numerical_derivatives(detmat_custom, ndim, nparticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b46d02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 7.22725872e-12,  2.26436903e-12,  2.99505473e-12],\n",
       "        [-3.18989626e-13,  2.73815345e-12,  8.62047933e-12],\n",
       "        [-3.75545428e-12, -5.04580752e-12, -4.85803758e-12]],\n",
       "\n",
       "       [[-2.99139880e-12, -7.19455745e-12, -1.86958088e-13],\n",
       "        [-1.72149404e-12, -1.01614051e-12, -1.65235057e-12],\n",
       "        [ 5.89765042e-12,  8.32850455e-12,  4.82140369e-13]]])>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error in the first derivative using the custom determinant, should be < 1e-6 (kick_size)\n",
    "c_num_dw_dx - c_dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df25f045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 5.23191461e-10,  7.25433989e-10,  5.42739781e-10],\n",
       "        [-1.15374940e-10,  2.72116184e-10,  7.50053152e-10],\n",
       "        [-4.77161054e-11, -3.80347212e-11, -1.53211839e-10]],\n",
       "\n",
       "       [[-1.16605593e-10, -1.92003261e-09, -2.26585155e-09],\n",
       "        [ 3.05527041e-09,  3.96548538e-09,  1.51798726e-09],\n",
       "        [ 4.78336239e-09,  4.26325480e-09,  4.15570045e-09]]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute error in the second derivative using the custom determinant, should be < 1e-6 (kick_size):\n",
    "c_num_d2w_dx2 - c_d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "361699aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[-2.87111961e-06, -6.83642841e-07, -5.33109269e-07],\n",
       "        [ 1.67814396e-07, -2.65826279e-07, -5.83178140e-07],\n",
       "        [ 1.33812327e-06,  8.86617710e-08,  4.26530228e-07]],\n",
       "\n",
       "       [[-1.03910932e-07, -1.53869089e-06, -2.27411448e-06],\n",
       "        [ 1.65420018e-05,  1.42675489e-05,  6.92292176e-06],\n",
       "        [-6.19091115e-06, -5.81504082e-06, -4.64110404e-06]]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the relative error in the second derivative using the custom operation:\n",
    "(c_num_d2w_dx2 - c_d2w_dx2)/c_num_d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0add1590",
   "metadata": {},
   "source": [
    "This custom determinant is in line with expectations from a numerical approximation of the 2nd derivative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1888f42f",
   "metadata": {},
   "source": [
    "## Derivatives with log determinant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b884cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x1641bcee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x1641a5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "log_w_of_x, log_dw_dx, log_d2w_dx2 = derivatives(logdetmat, tf.convert_to_tensor(inputs))\n",
    "log_num_dw_dx, log_num_d2w_dx2 = full_numerical_derivatives(logdetmat, ndim, nparticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c0ccec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 7.16275390e-12,  2.24241502e-12,  2.94030425e-12],\n",
       "        [-3.08143268e-13,  2.70320875e-12,  8.63188427e-12],\n",
       "        [-3.78174618e-12, -5.05935658e-12, -4.85289109e-12]],\n",
       "\n",
       "       [[-2.93745974e-12, -7.13880268e-12, -1.72663641e-13],\n",
       "        [-1.79237593e-12, -1.06337237e-12, -1.58892691e-12],\n",
       "        [ 5.93439859e-12,  8.38320982e-12,  5.81487332e-13]]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error in the first derivative using the log determinant, should be < 1e-6 (kick_size)\n",
    "log_num_dw_dx - log_dw_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93e1c63f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[-2.12144931e-03, -1.26565997e-04, -2.24313538e-04],\n",
       "        [ 7.94129972e-05,  3.33812677e-03,  5.88275189e-03],\n",
       "        [ 1.25819290e-03,  2.18056172e-03,  2.01692124e-03]],\n",
       "\n",
       "       [[ 5.33798062e-03,  8.45565487e-03,  2.21704051e-03],\n",
       "        [-4.88294903e-03, -1.45538992e-03, -3.61198767e-03],\n",
       "        [ 2.07485070e-02,  2.65361960e-02,  2.76021238e-03]]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Absolute error in the second derivative using the log determinant, should be < 1e-6 (kick_size):\n",
    "log_num_d2w_dx2 - log_d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "593a83c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[ 11.6418252 ,   0.11927465,   0.2203331 ],\n",
       "        [ -0.11550726,  -3.2609662 ,  -4.57393179],\n",
       "        [-35.28364784,  -5.083045  ,  -5.6149554 ]],\n",
       "\n",
       "       [[  4.7568459 ,   6.77625287,   2.2251186 ],\n",
       "        [-26.4377604 ,  -5.23644349, -16.47281571],\n",
       "        [-26.85381152, -36.19497695,  -3.08260865]]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare the relative error in the second derivative using the log operation:\n",
    "(log_num_d2w_dx2 - log_d2w_dx2)/log_num_d2w_dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f5aa15bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]])>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing the two tensorflow determinant techniques:\n",
    "d2w_dx2 - log_d2w_dx2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931d85e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "There is a bug in the tensorflow computation of a 2nd derivative of a determinant.  Both `tf.linalg.det` and `tf.linalg.slogdet` exhibit this bug, making me think this is a logic error.\n",
    "\n",
    "I assume the derivative of a determinant in practice is calculated with Jacobi's Formula (https://en.wikipedia.org/wiki/Jacobi%27s_formula)\n",
    "\n",
    "*Because the 2nd derivative using det and slogdet agree, I think there may be an error in a derivative of Jacobi's formula*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94a75d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
